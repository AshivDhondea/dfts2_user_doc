\chapter{Content-Adaptive Linear Tensor Completion} \label{chapter:caltec}

\section{Introduction} \label{sec:caltec:intro}
This chapter presents a new tensor completion method which is based on exploiting the correlation between co-located rows in different channels in a corrupted deep feature tensor. Section \ref{sec:caltec:motivation} provides the motivation behind \gls{caltec} in light of the existing \gls{altec} method. Based on the rationale behind the proposed method, Section \ref{sec:caltec:tensorviz} makes use of deep feature tensor visualizations to explain how \gls{caltec} works. With the help of a transmitted \gls{resnet18} tensor from an ostrich image (from the \textit{Imagenet} validation set), Section \ref{sec:caltec:ex} shows step by step results. Section \ref{sec:caltec:algo} documents the algorithm of the proposed method and Section \ref{sec:caltec:summary} summarizes the key points in this chapter.

\section{Motivation} \label{sec:caltec:motivation}
General tensor completion methods such as \gls{silrtc} and \gls{halrtc} do not make any assumptions about the spatial distribution of the lost elements in a tensor. These lost elements in a corrupt tensor may be assumed to be randomly distributed or they may be assumed to form contiguous rows or columns, such as the macro-blocks of data which constitute a packet in video streaming applications and in \gls{dfts}. There is a definite benefit in factoring in the nature of the distribution of lost elements in tensor data as was shown by the more recent \gls{altec}. Indeed, \gls{altec} has been specifically developed for deep feature tensors and it exploits the fact that lost elements constitute rows in a tensor \cite{9017944}. \gls{altec} assumes that a row of a deep feature tensor may be expressed as a linear combination of its immediate neighbors in-channel and its co-located rows in other channels \cite{9017944}.

\gls{altec} defines a packet to be a single row of data in a transmitted tensor. Considering packet 4 in channel 0 in Figure \ref{fig:altec}: its in-channel neighbors are highlighted in pink and its co-located packets in other channels are highlighted in green.
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.88]{Figures/tensoraltec.pdf}
	\caption[Packetization scheme adopted in ALTeC]{Packetization scheme adopted in \gls{altec}: each row in a channel of a deep feature tensor is treated as a packet. Lost packets are highlighted in blue. Packet 4 in channel 0's spatial neighbors in-channel are highlighted in pink and its co-located packets in other channels are highlighted in green.}
	\label{fig:altec}
\end{figure}
Weights used in the linear combination for each packet (identified as $\gls{pkt}_i^{(\gls{c})})$) in a channel $\gls{c}$ are pre-computed by training on an Imagenet validation set. They are then looked up from a table when \gls{altec} is completing a damaged tensor whose packet $\gls{pkt}_i^{(\gls{c})}$ was corrupted. In-channel neighbors or co-located packets may also be missing, in which case their weights were set to zero in the training stage \cite{9017944}. In essence, \gls{altec}'s results have shown that there is some structure within a \gls{dnn}'s tensors that may be successfully exploited to recover missing data.

Following this rationale, the new proposed method computes the weights online based on co-located packets out-of-channel and neighboring packets in-channel within the same corrupted tensor \gls{xda}. It is therefore content-adaptive. It is also linear in nature, since it estimates a repaired packet $\tilde{\gls{pkt}}$ as an affine transformation of its highest correlated co-located packet. Hence, this proposed method is called Content-Adaptive Linear Tensor Completion (\gls{caltec}).

\gls{caltec} does not require any prior training. Since it involves very few matrix and vector multiplication operations, it is fast, which may be a critical requirement in some \glslink{ci}{Collaborative Intelligence} applications.


\section{Rationale behind CALTeC} \label{sec:caltec:tensorviz}

%\begin{figure}[H]
%	\centering
%	\includegraphics[scale=1]{Figures/tiledoriginalbatch0item0.jpg}
%	\caption[Starfish original tensor visualization]{Starfish image: original \addone~tensor \gls{xtensor} visualization}
%	\label{fig:tensorviz:starfish:ori}
%\end{figure}

In the \gls{dfts} framework, packets are $\gls{rpp} \times \gls{w}$ strips of deep feature tensor values within a channel $\gls{h} \times \gls{w}$. Figure \ref{fig:tensorviz:starfish:da} is a visualization of a damaged \gls{resnet18} \addone~tensor $\gls{xda} \in \R^{56 \times 56 \times 64}$. Each $56 \times 56$ tile represents a channel $\gls{c}$ in the corrupted tensor. Missing packets appear as strips of black pixels.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.7]{Figures/tileddamagedbatch0item0.jpg}
	\caption[Starfish damaged tensor visualization]{Starfish image: corrupted \addone~tensor \gls{xda} visualization}
	\label{fig:tensorviz:starfish:da}
\end{figure}

From Figure \ref{fig:tensorviz:starfish:da}, it can be seen that there is a clear visual similarity between different channels of the corrupted tensor. This suggests that there is a degree of redundancy between the deep feature tensor channels. For instance, channel 0 (top left tile) can perhaps be represented as a weighted combination of channels 28 and 42. The weights may potentially be row and/or column dependent. So if a packet in channel 0 is missing, it can be `filled in' by exploiting its co-located packet in channels 28 and 42. The challenge of a potential tensor completion method is to first, find suitable candidate channels and second, correctly calculate the weights used to combine these redundant channels.

The proposed method \gls{caltec} makes use of the Pearson correlation coefficient as a measure of visual similarity between different channels, as will be explained below.

\section{CALTeC example} \label{sec:caltec:ex}

We use an example to explain the rationale behind \gls{caltec}. We consider a missing packet in a \gls{resnet18} \addone~tensor. As can be seen in Figure \ref{fig:tensorviz:ostrich:pkt2}, packets 2 and 5 are missing. The nearest correctly received spatial neighbors are packets 1 and 3 for the missing packet 2. The corresponding existing in-channel neighbors for packet $\gls{pkt}_5^{(16)}$ are $\gls{pkt}_4^{(16)}$ and $\gls{pkt}_6^{(16)}$. The nearest spatial neighbors in-channel are preferred by \gls{caltec} because local neighborhoods are more likely to have similar textures.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.7]{Figures/pkt2channel16tileddamagedbatch1item0.jpg}
	\caption[Ostrich damaged tensor visualization indicating damaged channel]{Ostrich image: in channel 16, packets 2 and 5 are missing in the \addone~tensor \gls{xda}}
	\label{fig:tensorviz:ostrich:pkt2}
\end{figure}

We consider the missing packet $\gls{pkt}_2^{(16)}$ and its nearest neighbor $\gls{pkt}_3^{(16)}$. 

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.7]{Figures/pkt2tileddamagedbatch1item0.jpg}
	\caption[Ostrich damaged tensor visualization: packet 2 in channel 16 is missing]{Ostrich image: missing packet 2 in channel 16 is represented as $\gls{pkt}_2^{(16)}$ (shaded in purple).}
	\label{fig:tensorviz:ostrich:pkt2p}
\end{figure}

\hl{interpretation needed for this figure.}

We list all channels which have correctly received co-located packets for indices 2 and 3. This candidate channels list is made up of every channel in the corrupted tensor except channels $[3,12,17,37,46,48]$. 

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.7]{Figures/pkt2allcandidatechcantileddamagedbatch1item0.jpg}
	\caption[Candidate packets three for correlation test]{Candidate packets $\gls{pkt}_3$ for correlation test with $\gls{pkt}_3^{(16)}$ are outlined with yellow lines in all channels of the corrupted deep feature tensor. Packets $\gls{pkt}_3^{(3)},\gls{pkt}_3^{(12)},\gls{pkt}_3^{(17)},\gls{pkt}_3^{(37)},\gls{pkt}_3^{(46)},\gls{pkt}_3^{(48)}$ (packets shaded in red) are rejected. Their corresponding channels are shaded in pink.}
	\label{fig:tensorviz:ostrich:candi}
\end{figure}

\hl{intepretation for this image.}



For this list of candidate channels, each packet 3 is reshaped to a vector $\gls{pkt}_3^{(c_i)} \mapsto \text{Vec}(\gls{pkt}_3^{(c_i)})$. The correlation coefficient between each vectorized candidate packet and the vectorized spatial neighbor packet $\gls{pkt}_3^{(16)}$ is calculated using the Pearson product-moment correlation coefficient formula, given below.

\begin{equation}
	\mathbf{R}_{ij} = \frac{\mathbf{C}_{ij}}{\sqrt{\mathbf{C}_{ii} \cdot \mathbf{C}_{jj}}}
\end{equation}

where $\mathbf{R}_{ij}$ is the Pearson correlation coefficient, $\mathbf{C}_{ij}$ is the covariance between the vectorized $\gls{pkt}_3^{(16)}$ and the vectorized candidate packet $\gls{pkt}_3^{(\gls{c}_i)}$. The highest correlated channel was channel 49.

\hl{stuff to fix here.}

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.7]{Figures/candidatechannel.jpg}
	\caption[Selected candidate packet with highest correlation coefficient]{The selected packet $\gls{pkt}_3^{(49)}$ (shaded in green) gives the highest correlation coefficient.}
\end{figure}

\hl{explain more.}


Figure \ref{fig:caltec:corrcoef} shows a plot of each row of the spatial neighbor packet in the damaged channel 16 and the corresponding row of the highest correlated out-of-channel packet.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.72]{Figures/ostrichchannel16pkt2corr.pdf}
	\caption[Ostrich image: row visualization of spatial neighbor packet]{Ostrich image: row visualization for the spatial neighbor packet $\gls{pkt}_3^{(16)}$ in the damaged channel and its co-located packet $\gls{pkt}_3^{(49)}$ in the candidate channel which gave the highest correlation coefficient.}
	\label{fig:caltec:corrcoef}
\end{figure}

By closely examining Figure \ref{fig:caltec:corrcoef}, we find that for many columns of these two packets, the graph for the in-channel row possesses a very similar shape to that of the out-of-channel row. Therefore, \gls{caltec} assumes that there exists a luminance transformation of the form $y=ax+b$ which can transform packet $\gls{pkt}_3^{(49)}$ into $\gls{pkt}_3^{(16)}$. The parameters $a$ and $b$ for scaling and shifting the intensity are found by performing a least squares fit between the vectorized versions of the two packets. The luminance transformation equation was found to be $\text{Vec}(\gls{pkt}_3^{(16)}) = -0.2298 \cdot \text{Vec}(\gls{pkt}_3^{(49)}) + 0.5537$.

Since packets $\gls{pkt}_3^{(16)}$ and $\gls{pkt}_3^{(49)}$ were found to be highly correlated and that they have definite visual similarities, we can assume that the same relationship should exist between the missing packet $\gls{pkt}_2^{(16)}$ and its co-located packet $\gls{pkt}_2^{(49)}$. We also assume that the same luminance transformation found previously can be used to transform the candidate packet $\gls{pkt}_2^{(49)}$ into the estimated packet $\tilde{\gls{pkt}}_2^{(16)}$. Therefore, \gls{caltec} performs a luminance transformation on the co-located packet of the highest correlated candidate channel and fills in the gap in the damaged channel.

Corrupted tensors are repaired by \gls{caltec} packet by packet. If the missing packet does not have an immediate neighbor which was correctly received, the nearest correctly received packet is utilized by \gls{caltec}. If all packets in a channel \gls{c} are missing, then \gls{caltec} is not able to make use of an existing spatial neighbor packet and hence, it has to give up on repairing that particular channel. In high loss (say $\gls{pb}=30\%$) scenarios with a Gilbert-Elliott unreliable channel model, \gls{caltec} may end up not finding any candidate channel based on the requirement that the candidate channel needs to have both the co-located packet and its neighbor packet to be available. Overall, \gls{caltec}'s execution time is correlated with the number of missing packets in a corrupted deep feature tensor.

Figure \ref{fig:caltec:ostrich:repaired} shows the \gls{caltec}-repaired \addone~\gls{xtc} tensor.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.7]{Figures/tiledcaltecbatch1item0.jpg}
	\caption[Ostrich image: CALTeC repaired tensor visualization]{Ostrich image: \gls{caltec}-repaired tensor visualization}
	\label{fig:caltec:ostrich:repaired}
\end{figure}

\gls{caltec}-repaired packets blend in their channel very well in terms of visual appearance. To get a better understanding of \gls{caltec}'s effect, we consider the row-wise plot of the original packet and the repaired packet in Figure \ref{fig:caltec:rowvis}.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.72]{Figures/ostrichchannel16pkt2caltec.pdf}
	\caption[Ostrich image: row visualization of original packet and completed packet]{Ostrich image: row visualization of the original packet and the \gls{caltec}-repaired packet}
	\label{fig:caltec:rowvis}
\end{figure}

In Figure \ref{fig:caltec:rowvis}, the ground truth refers to the (32-bit floating point) packet from the original deep feature tensor \gls{xtensor} before it was quantized and transmitted. While the repaired tensor's rows do not match exactly with the ground truth, they do approximate the original tensor's rows at a large number of indices. In general, it appears that there is a wider dynamic range of values in the ground truth data, which the luminance-transformed \gls{caltec} repaired packet $\hat{\gls{pkt}}_2^{(16)}$ cannot seem to match. 

%\section{Interesting examples} \label{sec:caltec:ex}
Figure \ref{fig:caltec:ostrich} shows the original channel 16, the damaged channel, the \gls{caltec}-repaired channel and the error between the repaired and original channels ($\gls{pkt}_2^{(16)} -\hat{\gls{pkt}}_2^{(16)} $).


	\begin{figure}[H]
	\centering
	\begin{subfigure}{.44\textwidth}
		\centering
		\includegraphics[width = \textwidth]{Figures/originalostrich162scaled.jpg}
		\caption{Original channel.}
	\end{subfigure}%
\hfill 
	\begin{subfigure}{.44\textwidth}
		\centering
		\includegraphics[width = \textwidth]{Figures/caltecostrich162scaled.jpg}
		\caption{CALTeC output.}
	\end{subfigure}
\hfill
	\begin{subfigure}{.44\textwidth}
	\centering
	\includegraphics[width = \textwidth]{Figures/ostrichdamagedscaled.jpg}
	\caption{Damaged channel.}
\end{subfigure}%
\hfill
	\begin{subfigure}{.44\textwidth}
	\centering
	\includegraphics[width = \textwidth]{Figures/diffostrichscaled.jpg}
	\caption{Error in completion.}
\end{subfigure}%
	\caption[Channel 16 visualization in a damaged image ResNet18 tensor]{Channel 16 in a damaged \gls{resnet18} \addone~tensor. (Note that these images were scaled up from their original $56 \times 56$ size by a factor of 5 using bicubic interpolation.)}
	\label{fig:caltec:ostrich}
\end{figure}

There are slight differences between the original and the completed tensor, which hopefully will not affect the cloud model's prediction performance.

\section{CALTeC algorithm} \label{sec:caltec:algo}

This section provides the \gls{caltec} algorithm. The inputs to the function are the corrupted tensor \gls{xda} and the loss packet map, which is a Boolean matrix. Assuming that each channel in the corrupted deep feature tensor is made up of $n$ packets and that there are $d$ channels in the tensor, the loss packet map is then $n \times d$. If element $(i,j)$ is \verb|False|, then it means packet $i$ in channel $j$ is missing. Therefore, the loss packet map can be readily exploited to list all channels which correctly received a packet $\gls{pkt}_i$.

\begin{algorithm}[H]
	\caption[CALTeC algorithm]{\gls{caltec} algorithm} \label{algo:caltec}
	\begin{algorithmic}
		\Procedure{\texttt{CALTeC}}{$\gls{xda}$, map}
		%\State Get num\_channels, channel\_width, $\gls{rpp}$ from \gls{xda}
		\State $\gls{xtc} \gets \gls{xda}$
		\For{$\gls{c}_i \in \gls{xda}$} \Comment{Loop through all channels of the tensor.}
		\If{$\text{map}(\gls{c}_i) \equiv \text{False}  ~\forall~i$}
		\Continue \Comment{Cannot repair a channel when all packets are missing.}
		\Else
		\For{$\gls{pkt}_i^{(\gls{c})} \in \gls{c}$}
		\If{$\text{map}(\gls{c}_i) \equiv \text{False}$} \Comment{If packet is missing.}
		\State Accumulate list $\mathcal{E}$ of all existing packets in channel \gls{c}.
		\State From the list $\mathcal{E}$, find the nearest packet $\gls{pkt}_{\text{n}}$ to missing packet.
		\State Accumulate list $\mathcal{S}$ of all channels $\mathbf{s}$ with $\text{map}(\mathbf{s}_i) \equiv \text{True}$.
		\State Accumulate list $\mathcal{T}$ of all channels $\mathbf{t}$ with $\text{map}(\mathbf{t}_n) \equiv \text{True}$.
		\State $\mathcal{C} = \mathcal{S} \cap \mathcal{T}$. \Comment{Channels which possess both packet $\gls{pkt}_i$ and $\gls{pkt}_n$.}
		\If{$|\mathcal{C}| \equiv 0$} \Comment{No candidate channel found.}
		\Continue
		\EndIf
		\State $\mathbf{R} \gets \text{corr}(\text{Vec}(\gls{pkt}_n^{(\gls{c})}),\text{Vec}(\gls{pkt}_n^{(\mathbf{k})}))~\forall~ \mathbf{k} \in \mathcal{C}$ \Comment{Pearson correlation coefficient}
		\State $\mathbf{b} \gets \argmax_{\mathbf{k}}(\mathbf{R})$ \Comment{Candidate channel with highest correlation coefficient}
		\State $f \gets \mathtt{luminance\_transform}(\text{Vec}(\gls{pkt}_n^{(\gls{c})},\text{Vec}(\gls{pkt}_n^{(\mathbf{b})})$
		\State $\text{Vec}(\hat{\gls{pkt}}_i^{(\gls{c})}) \gets f(\text{Vec}(\gls{pkt}_i^{(\mathbf{b})})) $
		\State $ \hat{\gls{pkt}}_i^{(\gls{c})} \gets \text{Vec}(\hat{\gls{pkt}}_i^{(\gls{c})})$ \Comment{Reshape into matrix form}
			\State Update \gls{xtc} with $\hat{\gls{pkt}}_i^{(\gls{c})}$
		\EndIf
		\EndFor 
		\EndIf
		
		\EndFor		
		\EndProcedure
		\Procedure{\texttt{luminance\_transform}}{$\mathbf{p}$,$\mathbf{q}$}
		\State Find $a,b$ which minimize $J(a,b) = \big[\mathbf{p} - (a\mathbf{q}+b)\big]^2$ using least squares estimation.
		\State $f \gets ax + b$
		\EndProcedure
		\end{algorithmic}
\end{algorithm}

\section{Summary} \label{sec:caltec:summary} 

This chapter has discussed in detail the rationale behind the operation of the proposed tensor completion method. It has shown visual results to motivate its design and prove its performance. The following chapter will discuss how experiments were run to obtain quantitative results for this proposed method. Given that \gls{caltec} does not make use of computationally expensive operations such as Singular Value Decomposition (in contrast with general tensor completion methods), it has a more muted impact on the inference latency of the cloud sub-model in applications which employ a \glslink{ci}{Collaborative Intelligence} strategy. Since the number of computations depends on the amount of missing packets in a corrupted tensor, \gls{caltec} has minimal execution times when transmitted tensors have relatively few lost packets, unlike general tensor completion methods, such as \gls{silrtc} and \gls{halrtc}. This is highly advantageous in \gls{ci} applications in which inference latency is crucial.