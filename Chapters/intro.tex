\chapter{Introduction} \label{chapter:intro}
Recent deep neural network models (\gls{dnn}s) achieve impressive results in deep learning tasks such as image classification and object detection. The ever-improving performance comes at the cost of increased computational complexity. The status quo approach for inference tasks with deep models is either mobile-only or cloud-only. Cloud services can usually readily handle sophisticated \gls{dnn}s. However, sophisticated models deployed on mobile devices may pose a challenge in terms of power usage and inference latency. 

Collaborative intelligence (\gls{ci}) is a hybrid approach which leverages edge-based and cloud-based resources to accelerate inference with deep models on edge devices \cite{neurosurgeon,jointdnn,8451100,8803110,choi2018deep,alvar2020bit,9017944}. It entails splitting a \gls{dnn} into a mobile or edge sub-model and a remote or cloud sub-model. Deep feature tensors are compressed and transmitted from the mobile device to the cloud. As shown in Figure \ref{fig:ci}, the deep feature tensors output by the initial few layers of the deep model are transmitted over an imperfect channel. The remaining layers of the deep model implemented in the cloud operate on these received tensors to make an inference on the original input image of a tree.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{Figures/image--000.png}
	\caption{Blueprint for Collaborative Intelligence.\cite{neurosurgeon}}
	\label{fig:ci}
\end{figure}

The channel between the mobile device and the cloud service is imperfect in the sense that the transmitted data may be damaged or lost due to various reasons. These include errors occurring in data transmission (e.g. weak WiFi signal) and network congestion (e.g. in cellular networks). The damaged or lost data may adversely affect the cloud sub-model's inference task. 

To study the impact of imperfect channels on \glslink{ci}{collaborative intelligence}, the \glslink{dfts}{Deep Feature Transmission Simulator} was developed at Simon Fraser University's Multimedia Lab. In the framework of \gls{ci}, it could split a deep model into a mobile or edge sub-model and a cloud sub-model. For example, a smartphone user may snap a photograph of a group of unknown animals at the zoo. Their smartphone will run the initial few layers of the deep model and transmit the output tensors over an LTE network to the cloud which will execute the remaining \gls{dnn} computing. As shown in Figure \ref{fig:splitting}, the deep model (a \gls{vgg16}) is split into two sub-models at the output of the third block of layers.

\begin{figure}[H]
	\centering
	\includegraphics[scale = 0.4]{Figures/vgg16CI.pdf}
	\caption{Splitting a deep model into two sub-models: the mobile device or edge sub-model and the remote or cloud sub-model.}
	\label{fig:splitting}
\end{figure}

The tensor output by this block is transmitted over an imperfect channel of given characteristics. The cloud service then does the remaining computations of \gls{vgg16} to complete the inference task. The cloud service provides the inferred label `Meerkat' to the smartphone user. This is an example of an image classification task which can be simulated in \gls{dfts}. Deep feature tensors produced by edge sub-models are quantized, packetized and transmitted over unreliable channels, which results in the cloud receiving damaged deep feature tensors. Tensor error concealment methods can be implemented in the cloud to improve the split deep model's inference performance. Given the needs of developing fields such as the Internet of Things (IoT), \glslink{ci}{collaborative intelligence} will prove itself to be an important deployment strategy. Therefore, it is highly beneficial to develop methods to accurately reconstruct damaged or missing deep features in transmitted tensors in a \gls{ci} context. 

In this project, we focus on the image classification task with a \gls{dnn} in a \gls{ci} deployment framework. We introduce a new tensor completion method, namely Content-Adaptive Linear Tensor Completion (\gls{caltec}), and we benchmark its performance against two general tensor completion methods (\gls{silrtc} and \gls{halrtc}). We report on updating \gls{dfts} and extending it to simulate more complex scenarios. We also discuss experiments which study the effect of compressing deep feature tensors originating from mobile sub-models. We study the impact of channel parameters on cloud image classification performance with a \gls{vgg16} and a \gls{resnet18}.


\section{Objectives of the study}
The main objectives of this work are to study transmission of deep features over an imperfect channel and to develop a new tensor completion method. Given that the original \gls{dfts} was developed in the soon-to-be-deprecated TensorFlow 1 framework, it was necessary to update the simulator to gain compatibility with TensorFlow version 2. This will allow users to perform collaborative intelligence experiments with state of the art \gls{dnn}s. 

\section{Notation}
Before delving further into the field of deep feature transmission, we establish the notation used in this work. A deep feature tensor, such as the tensor originating from \verb|block3| of the device sub-model in the \gls{vgg16} architecture of Figure \ref{fig:splitting}, is three dimensional, as shown in Figure \ref{fig:intro:tensor}.

\begin{figure}[H]
	\centering
	\includegraphics[scale=1]{Figures/tensor.pdf}
	\caption[Visualization of a generic tensor]{Visualization of a generic tensor \gls{xtensor}.}
	\label{fig:intro:tensor}
\end{figure}

A generic tensor \gls{xtensor} in this report is $\gls{h} \times \gls{w} \times \# \gls{c}$. For all scenarios considered in this work, the height and the width of a channel were identical, so $\gls{h} \equiv \gls{w}$. The tensor can be represented in mathematical terms as
\begin{equation}
	\gls{xtensor} = \begin{pmatrix}
		\begin{bmatrix}
			9 & 14 & 13 & 13 \\
			20 & 4 & 16 & 13 \\
			23 & 21 & 12 & 25\\
			12 & 14 & 13 & 16
		\end{bmatrix}
	,
	\begin{bmatrix}
		16 & 11 & 23 & 24 \\
		6 & 9 & 3 & 2 \\
		12 & 31 & 26 & 9 \\
		21 & 21 & 7 & 21\\
	\end{bmatrix}
,
\begin{bmatrix}
	30 & 26 & 13 & 8 \\
	30 & 25 & 5 & 9 \\
	14 & 17 & 2 & 0\\
	20 & 10 & 28 & 3
\end{bmatrix}
,
\begin{bmatrix}
	27 & 17 & 22 & 20 \\
	8 & 0 & 24 & 13 \\
	0 & 19 & 31 & 26 \\
	26 & 17 & 2 & 0
\end{bmatrix}
	\end{pmatrix}
\end{equation}

In \gls{dfts}, macro-blocks of data are considered to be packets. For instance, assuming that two rows of deep features constitute a packet \gls{pkt} (that is, the number of feature rows per packet $\gls{rpp} = 2$), each $\gls{h} \times \gls{w}$ channel \gls{c} is made up of $\nicefrac{h}{2}$ packets. Zero padding may be applied to channels in case the number of rows is not an integer multiple of the desired packet size. The packetization scheme, illustrated in Figure \ref{fig:1:pkts}, is similar to those adopted in video streaming applications. Due to the unreliable nature of the communication channel between the edge device and the cloud service, some data packets may be lost or they may be considered to be lost if, for example, a Cyclic Redundancy Check (CRC) fails.


\begin{figure}[H]
	\centering
	\includegraphics[scale=0.85]{Figures/tensorlost.pdf}
	\caption[Visualization of a damaged tensor]{Visualization of a damaged tensor $\gls{xda} \in \R^{8 \times 8 \times 4}$. Highlighted pairs of rows correspond to lost packets.}
	\label{fig:1:pkts}
\end{figure}

As can be seen in Figure \ref{fig:1:pkts}, a channel comprises 8 rows of features mapped into packets 0 through 3. Lost feature values are represented by question marks (`?') to indicate that they are not available to the cloud sub-model for computation. These `holes' may be filled by employing a tensor completion method with the overall objective being to assist the cloud sub-model in completing the inference task. Bursts of packet loss may also occur. For instance, in channel $\gls{c} = 3$ in Figure \ref{fig:1:pkts}, packets $\gls{pkt}_0^{(3)},\gls{pkt}_1^{(3)},\gls{pkt}_2^{(3)}$ are missing.

Figure \ref{fig:intro:starfish:da} is a visualization of a \gls{resnet18} \addone~tensor $\gls{xda} \in \R^{56 \times 56 \times 64}$. Each $56 \times 56$ tile represents a channel $\gls{c}$ in the corrupted tensor. Missing packets appear as strips of black pixels.

\begin{figure}[H]
	\centering
	\includegraphics[scale=1]{Figures/tileddamagedbatch0item0.jpg}
	\caption[Starfish damaged tensor visualization]{Starfish image: corrupted \addone~tensor \gls{xda} visualization. Packets are $8 \times 56$ blocks of deep feature tensor values.}
	\label{fig:intro:starfish:da}
\end{figure}

The objective of a tensor completion method is to `fill in' the gaps which represent lost packets in damaged channels of \gls{xda} in order to estimate a tensor \gls{xtc} which needs to be as close as possible to the original tensor \gls{xtensor}. The `completed' tensor \gls{xtc} is passed on to the cloud sub-model which then completes the inference task. The accuracy and latency of inference are thus directly affected by the performance of the tensor completion method employed.

\section{Project overview}
This report is organized as follows. Chapter \ref{chapter:background} reviews the literature on collaborative intelligence. It discusses general tensor completion methods which were implemented in the new \gls{dfts}, namely \gls{silrtc} - Simple Low Rank Tensor Completion and \gls{halrtc} - High accuracy Low Rank Tensor Completion. It also discusses \gls{altec} - Adaptive Linear Tensor Completion, a recent deep feature tensor completion method developed in the \glslink{ci}{Collaborative Intelligence} framework. Based on the conclusions drawn from the literature review, Chapter \ref{chapter:caltec} develops the proposed tensor completion method \gls{caltec} - Content Adaptive Linear Tensor Completion. It discusses in detail the operation of \gls{caltec}, with tensor visualizations and provides the algorithm which can be used to implement this proposed tensor completion method. Chapter \ref{chapter:expts} discusses the experiments designed and performed in the course of this project. It reports on Monte Carlo experiments run to obtain tensor completion results with various unreliable channel realizations. It provides quantitative results on the performance of the proposed method, \gls{caltec}, and two general tensor completion methods from the literature. Finally, chapter \ref{chapter:conclusions} summarizes the conclusions drawn from this project and puts forth recommendations for future work. Appendix \ref{appendix:a} details the algorithms of the general tensor completion methods added to \gls{dfts} in this work.
